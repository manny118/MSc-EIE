{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author: Emmanuel Akinrintoyo\n",
    "# Import some Python libraries\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import math as TFmath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.seterr(divide = 'ignore')\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean absolute error\n",
    "def customLoss(y_actual, y_pred):\n",
    "  # Calculate the number of loaded channel\n",
    "  no_loaded_channels = tf.dtypes.cast(TFmath.count_nonzero(y_actual),\n",
    "                                      tf.float32)\n",
    "  # Set the values of the unloaded channels to zero\n",
    "  modified_y_pred = TFmath.divide_no_nan(TFmath.multiply(y_pred, y_actual),\n",
    "                                         y_actual)\n",
    "  # Calculate the loss\n",
    "  error = TFmath.abs(TFmath.subtract(modified_y_pred, y_actual))\n",
    "  loss = TFmath.divide(TFmath.reduce_sum(error), no_loaded_channels)\n",
    "  return loss\n",
    "\n",
    "\n",
    "# Plot the loss history\n",
    "def plotLoss(history):\n",
    "  plt.figure(0)\n",
    "  plt.plot(history.history['loss'], label='loss')\n",
    "  plt.plot(history.history['val_loss'], label='val_loss')\n",
    "  plt.xlabel('Epochs', fontsize=16)\n",
    "  plt.ylabel('Error', fontsize=16)\n",
    "  plt.legend()\n",
    "  plt.grid(True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the inputted dB values to absolute\n",
    "def convert2Linear(values):\n",
    "  return np.power(10, (values / 10))\n",
    "\n",
    "\n",
    "# Convert the linear values to dB\n",
    "def convert2dB(values):\n",
    "  return 10 * np.log10(values)\n",
    "\n",
    "\n",
    "# Build and compile the model\n",
    "def buildModel(normalization_layer, output_layer):\n",
    "  model = keras.Sequential([\n",
    "\n",
    "      normalization_layer,\n",
    "      layers.Dense(no_of_input_features, activation='relu', name='fc1'),\n",
    "      layers.Dense(256, activation='relu', name='fc2'),\n",
    "      layers.Dense(128, activation='relu', name='fc3'),\n",
    "      layers.Dense(128, activation='relu', name='fc4'),\n",
    "      layers.Dense(128, activation='relu', name='fc5'),\n",
    "      layers.Dense(output_layer)\n",
    "  ])\n",
    "  model.compile(loss=customLoss,\n",
    "                optimizer=tf.keras.optimizers.Adam(learning_rate=0.01))\n",
    "  return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input features consist of the target gain, total input power,\n",
    "# total output power, 94 channels' input powers and their status\n",
    "no_of_channels = 94\n",
    "no_of_input_features = (no_of_channels * 2) + 3\n",
    "\n",
    "# Store the names of the .csv files for the data\n",
    "train_data = \"../../data/train.csv\"\n",
    "valid_data = \"../../data/valid.csv\"\n",
    "test_data = \"../../data/test.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generates the names of columns used in the data for 94 channels\n",
    "def generateColumnNames(column_name):\n",
    "  labels_list = []\n",
    "  for i in range(1, no_of_channels + 1):\n",
    "\n",
    "    # convert the integer to a string\n",
    "    num = f'{i}'\n",
    "    if i < 10:\n",
    "      num = '0' + num\n",
    "    # Store each label\n",
    "    labels_list.append(column_name + num)\n",
    "\n",
    "  # Return the names for the corresponding 94 channels\n",
    "  return labels_list\n",
    "\n",
    "# Store the column names in the data\n",
    "column_names = ['target_gain',\n",
    "                'EDFA_input_spectra_',\n",
    "                'DUT_WSS_activated_channel_index_',\n",
    "                'calculated_gain_spectra_']\n",
    "\n",
    "# Store the complete column names for all channels\n",
    "input_spectra_columns = generateColumnNames(column_names[1])\n",
    "onehot_channels_columns = generateColumnNames(column_names[2])\n",
    "output_spectra_columns = generateColumnNames(column_names[3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the incomplete column names\n",
    "del column_names[1:4]\n",
    "\n",
    "# Reconstruct the column names\n",
    "column_names = column_names + input_spectra_columns + output_spectra_columns\n",
    "column_names_copy = column_names + onehot_channels_columns\n",
    "\n",
    "# Extract the names of all the columns excluding the first (i.e, target_gain)\n",
    "modified_columns = column_names[1:len(column_names)]\n",
    "column_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the data for the train, test and valid sets\n",
    "train_set = pd.read_csv(train_data, index_col=0)\n",
    "test_set = pd.read_csv(test_data, index_col=0)\n",
    "valid_set = pd.read_csv(valid_data, index_col=0)\n",
    "\n",
    "# Convert the values read to the linear scale\n",
    "train_set[modified_columns] = convert2Linear(train_set[modified_columns])\n",
    "test_set[modified_columns] = convert2Linear(test_set[modified_columns])\n",
    "valid_set[modified_columns] = convert2Linear(valid_set[modified_columns])\n",
    "\n",
    "train_set = train_set[column_names_copy]\n",
    "test_set = test_set[column_names_copy]\n",
    "valid_set = valid_set[column_names_copy]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_rows', None,\n",
    "                       'display.max_columns', None,\n",
    "                       'display.precision', 3,\n",
    "                       ):\n",
    "    display(valid_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the target value from the features.\n",
    "# target value - \"label\"\n",
    "# Label is the value that the model is trained to predict.\n",
    "def popLabels(features, result_labels):\n",
    "  output = pd.DataFrame()\n",
    "  for i in result_labels:\n",
    "    output = pd.concat([output, features.pop(i)], axis=1)\n",
    "  return output\n",
    "\n",
    "train_features = train_set.copy()\n",
    "train_labels = popLabels(train_features, output_spectra_columns)\n",
    "\n",
    "test_features = test_set.copy()\n",
    "test_labels = popLabels(test_features, output_spectra_columns)\n",
    "\n",
    "valid_features = valid_set.copy()\n",
    "valid_labels = popLabels(valid_features, output_spectra_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the gain value of the unloaded channels to zero\n",
    "def setActivatedChannels(labels, features, onehot_channels):\n",
    "  activated_channels = labels.values * features[onehot_channels].values\n",
    "  labels = pd.DataFrame(activated_channels, columns=labels.columns,\n",
    "                        index=labels.index)\n",
    "  return labels\n",
    "\n",
    "train_labels = setActivatedChannels(train_labels, train_features,\n",
    "                                    onehot_channels_columns)\n",
    "\n",
    "test_labels = setActivatedChannels(test_labels, test_features,\n",
    "                                   onehot_channels_columns)\n",
    "\n",
    "valid_labels = setActivatedChannels(valid_labels, valid_features,\n",
    "                                    onehot_channels_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a normalisation layer\n",
    "normalizer = layers.Normalization(axis=-1)\n",
    "normalizer.adapt(train_features)\n",
    "\n",
    "# Build the model and show its summary\n",
    "model = buildModel(normalizer, no_of_channels)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_features, train_labels, epochs=350, verbose=2,\n",
    "                    validation_data=(valid_features, valid_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the training progress of the model\n",
    "hist = pd.DataFrame(history.history)\n",
    "hist['epoch'] = history.epoch\n",
    "hist.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotLoss(history)\n",
    "plt.savefig('lossplot.eps', format='eps', dpi=900, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the test set results\n",
    "test_results = {}\n",
    "test_results['model'] = model.evaluate(test_features, test_labels, verbose=2)\n",
    "results = pd.DataFrame(test_results, index=['Mean absolute error [Gain]']).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions with the model\n",
    "test_predictions = model.predict(test_features)\n",
    "\n",
    "# Perform a conversion to dB\n",
    "test_predictions_dB = convert2dB(test_predictions)\n",
    "test_labels_dB = convert2dB(test_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1)\n",
    "font_size = 16\n",
    "\n",
    "# Show the predicted and meeasured gain values on a scatter plot\n",
    "plt.scatter(test_labels_dB, test_predictions_dB)\n",
    "plt.xlabel('Measured EDFA Gain (dB)', fontsize=font_size)\n",
    "plt.ylabel('Predicted EDFA Gain (dB)', fontsize=font_size)\n",
    "\n",
    "# Set the dimension values\n",
    "lims = [*np.arange(11, 16.2, 1)]\n",
    "limits = [lims[0], lims[len(lims) - 1]]\n",
    "plt.xlim(limits)\n",
    "plt.ylim(limits)\n",
    "plt.plot(limits, limits, 'b--')\n",
    "plt.savefig('regression_plt.eps', format='eps', dpi=900, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the error distribution\n",
    "plt.figure(2)\n",
    "error = (test_labels_dB - test_predictions_dB).to_numpy()\n",
    "error = [i for i in np.reshape(error, -1) if i > -10]\n",
    "\n",
    "# Set the bin values\n",
    "bins_list = [*np.arange(-1.2, 0.7, 0.1)]\n",
    "\n",
    "# Plot the histogram of the errors\n",
    "plt.hist(error, bins=bins_list)\n",
    "\n",
    "# Add vertical lines to the plot\n",
    "for i in [-0.2, -0.1, 0.1, 0.2]:\n",
    "  plt.axvline(x=i, color='black', ls='--')\n",
    "\n",
    "plt.xlabel('Prediction Gain Error (dB)', fontsize=font_size)\n",
    "plt.ylabel('Instances', fontsize=font_size)\n",
    "label_list = ['-1.2', '', '-1.0', '', '-0.8', '', '-0.6', '', '-0.4',\n",
    "              '', '-0.2', '', '0.0', '', '0.2', '', '0.4', '', '0.6']\n",
    "\n",
    "plt.xticks(ticks=bins_list, labels=label_list, fontsize=font_size)\n",
    "plt.yticks(fontsize=font_size)\n",
    "plt.savefig('histogram_plt.eps', format='eps', dpi=900, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the error values are within 0.2 dB and 0.1 dB\n",
    "reasonable_error = [i for i in error if abs(i) <= 0.2]\n",
    "reasonable_error2 = [i for i in error if abs(i) <= 0.1]\n",
    "print(\"Error <= 0.1 dB: {:.3f}\".format(len(reasonable_error2) / len(error)))\n",
    "print(\"Error <= 0.2 dB: {:.3f}\".format(len(reasonable_error) / len(error)))\n",
    "print(\"Error > 0.2 dB: {:.3f}\".format(1 - len(reasonable_error) / len(error)))\n",
    "\n",
    "error = (np.square(error)).mean(axis=None)\n",
    "print(\"MSE(all): {:.6f}\".format(error))\n",
    "\n",
    "error = (np.absolute(error)).mean(axis=None)\n",
    "print(\"MAE(all): {:.6f}\".format(error))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register the custom loss function..\n",
    "tf.keras.utils.register_keras_serializable(\n",
    "    package='custom_loss', name=customLoss\n",
    ")\n",
    "\n",
    "# Save the trained model\n",
    "model.save('LineAmp')\n",
    "print('Model saved')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
